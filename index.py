"""
FastAPI åº”ç”¨ï¼šå®ç° RAG é—®ç­”ç³»ç»Ÿ
"""
import os
import json
import re
import numpy as np
from typing import List, Optional, Tuple
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer
import openai
from dotenv import load_dotenv
from supabase import create_client, Client
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä¼˜å…ˆåŠ è½½ .env.localï¼Œç„¶ååŠ è½½ .envï¼‰
load_dotenv('.env.local')  # å…ˆåŠ è½½ .env.localï¼ˆå¦‚æœå­˜åœ¨ï¼‰
load_dotenv()  # å†åŠ è½½ .envï¼ˆ.env ä¸­çš„å€¼ä¼šè¦†ç›– .env.localï¼‰

app = FastAPI(title="RAG é—®ç­”ç³»ç»Ÿ")

# é…ç½® CORSï¼Œå…è®¸å‰ç«¯è®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],  # Next.js é»˜è®¤ç«¯å£
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
model = None
chunks = None
embeddings = None
chunk_game_names: Optional[List[Optional[str]]] = None  # æ¯ä¸ª chunk æ‰€å±çš„æ¸¸æˆåç§°
supabase: Optional[Client] = None
current_game_name: Optional[str] = None  # å½“å‰æ”»ç•¥çš„æ¸¸æˆåç§°

class QuestionRequest(BaseModel):
    question: str
    top_k: Optional[int] = 3  # è¿”å›æœ€ç›¸ä¼¼çš„æ®µè½æ•°é‡

class QuestionResponse(BaseModel):
    answer: str
    relevant_chunks: List[str]
    source: str  # "rag" æˆ– "llm_generated" æˆ– "llm_general"
    game_name: Optional[str] = None  # æ£€æµ‹åˆ°çš„æ¸¸æˆåç§°

def identify_game_from_chunk(chunk: str) -> Optional[str]:
    """
    ä» chunk å†…å®¹ä¸­è¯†åˆ«æ¸¸æˆåç§°
    æ”¯æŒæ ¼å¼ï¼š<<æ¸¸æˆå>>ã€æ¸¸æˆåæ”»ç•¥ã€æ¸¸æˆåç›¸å…³å…³é”®è¯
    """
    # å°è¯•åŒ¹é… <<æ¸¸æˆå>> æ ¼å¼
    match = re.search(r'<<([^>>]+)>>', chunk)
    if match:
        return match.group(1).strip()
    
    # å°è¯•åŒ¹é…ã€Šæ¸¸æˆåã€‹æ ¼å¼
    match = re.search(r'ã€Š([^ã€‹]+)ã€‹', chunk)
    if match:
        return match.group(1).strip()
    
    # å°è¯•åŒ¹é… "æ¸¸æˆå" æˆ– 'æ¸¸æˆå' æ ¼å¼
    match = re.search(r'["\']([^"\']+?)["\']', chunk)
    if match:
        candidate = match.group(1).strip()
        if len(candidate) >= 2 and len(candidate) <= 30:
            return candidate
    
    # å¦‚æœ chunk å¼€å¤´åŒ…å«æ˜æ˜¾çš„æ¸¸æˆåç§°æ¨¡å¼
    # ä¾‹å¦‚ï¼šæ¸¸æˆå + ç©ºæ ¼/æ¢è¡Œ + æ”»ç•¥å†…å®¹
    lines = chunk.split('\n')
    if lines:
        first_line = lines[0].strip()
        # å¦‚æœç¬¬ä¸€è¡Œè¾ƒçŸ­ä¸”ä¸åŒ…å«å¸¸è§åŠ¨è¯ï¼Œå¯èƒ½æ˜¯æ¸¸æˆå
        if len(first_line) >= 2 and len(first_line) <= 30:
            # æ’é™¤æ˜æ˜¾ä¸æ˜¯æ¸¸æˆåçš„å†…å®¹ï¼ˆåŒ…å«å¸¸è§åŠ¨è¯ã€æ ‡ç‚¹ç­‰ï¼‰
            if not re.search(r'[=ï¼š:ï¼Œ,ã€‚.ï¼!ï¼Ÿ?]', first_line):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡å•è¯
                if re.search(r'[\u4e00-\u9fa5A-Za-z]', first_line):
                    return first_line
    
    return None

def load_game_sequence_from_guide(guide_file: str = 'guide.txt') -> list:
    """
    ä» guide.txt è¯»å–æ¸¸æˆåºåˆ—ä¿¡æ¯
    è¿”å›: [(æ¸¸æˆåç§°, åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„ä½ç½®ä¿¡æ¯)]
    ç”¨äºç¡®å®šæ¯ä¸ªæ¸¸æˆåœ¨æ–‡æœ¬ä¸­çš„ä½ç½®èŒƒå›´
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    guide_path = os.path.join(script_dir, guide_file)
    
    if not os.path.exists(guide_path):
        return []
    
    game_sequence = []
    
    with open(guide_path, 'r', encoding='utf-8') as f:
        content = f.read()
        # æ‰¾åˆ°æ‰€æœ‰æ¸¸æˆæ ‡è¯†ç¬¦çš„ä½ç½®
        for match in re.finditer(r'<<([^>>]+)>>', content):
            game_name = match.group(1).strip()
            start_pos = match.start()
            game_sequence.append((game_name, start_pos))
    
    return game_sequence

def load_vectors(vector_file: str = 'guide_vectors.json'):
    """
    åŠ è½½é¢„ç”Ÿæˆçš„å‘é‡ï¼Œå¹¶ä¸ºæ¯ä¸ª chunk æ ‡è®°æ‰€å±æ¸¸æˆ
    è§„åˆ™ï¼š<<æ¸¸æˆå>> æ ‡è¯†ç¬¦åé¢çš„æ‰€æœ‰å†…å®¹éƒ½å±äºè¯¥æ¸¸æˆï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ª <<æ¸¸æˆå>>
    """
    global chunks, embeddings, chunk_game_names
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    vector_path = os.path.join(script_dir, vector_file)
    
    if not os.path.exists(vector_path):
        raise FileNotFoundError(
            f"å‘é‡æ–‡ä»¶ {vector_path} ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ vectorize_guide.py ç”Ÿæˆå‘é‡ã€‚"
        )
    
    with open(vector_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    chunks = data['chunks']
    embeddings = np.array(data['embeddings'])
    
    # ä¸ºæ¯ä¸ª chunk è¯†åˆ«æ‰€å±æ¸¸æˆ
    # è§„åˆ™ï¼šå¦‚æœ chunk ä¸­åŒ…å« <<æ¸¸æˆå>>ï¼Œåˆ™è®¾ç½®å½“å‰æ¸¸æˆä¸ºè¯¥æ¸¸æˆ
    # ä¹‹åçš„æ‰€æœ‰ chunks éƒ½ç»§æ‰¿è¿™ä¸ªæ¸¸æˆåç§°ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ª <<æ¸¸æˆå>>
    chunk_game_names = []
    current_game = None
    
    for i, chunk in enumerate(chunks):
        # æ£€æŸ¥ chunk ä¸­æ˜¯å¦åŒ…å«æ¸¸æˆæ ‡è¯†ç¬¦ <<æ¸¸æˆå>>
        match = re.search(r'<<([^>>]+)>>', chunk)
        if match:
            # æ‰¾åˆ°æ–°çš„æ¸¸æˆæ ‡è¯†ç¬¦ï¼Œæ›´æ–°å½“å‰æ¸¸æˆ
            current_game = match.group(1).strip()
            chunk_game_names.append(current_game)
        else:
            # æ²¡æœ‰æ¸¸æˆæ ‡è¯†ç¬¦ï¼Œç»§æ‰¿ä¸Šä¸€ä¸ª chunk çš„æ¸¸æˆåç§°
            # è¿™æ ·å¯ä»¥ç¡®ä¿ <<æ¸¸æˆå>> åé¢çš„æ‰€æœ‰å†…å®¹éƒ½å±äºè¯¥æ¸¸æˆ
            chunk_game_names.append(current_game)
    
    # ç»Ÿè®¡æ¸¸æˆåˆ†å¸ƒ
    game_stats = {}
    for game_name in chunk_game_names:
        if game_name:
            game_stats[game_name] = game_stats.get(game_name, 0) + 1
    
    print(f"å·²åŠ è½½ {len(chunks)} ä¸ªå‘é‡æ®µè½")
    if game_stats:
        print(f"æ£€æµ‹åˆ° {len(game_stats)} ä¸ªæ¸¸æˆçš„æ”»ç•¥:")
        for game, count in sorted(game_stats.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {game}: {count} ä¸ªæ®µè½")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°æ¸¸æˆåç§°æ ‡è®°ï¼Œæ‰€æœ‰æ®µè½å°†è§†ä¸ºé€šç”¨å†…å®¹")

def init_supabase():
    """
    åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
    """
    global supabase
    if supabase is None:
        # å°è¯•å¤šç§ç¯å¢ƒå˜é‡åç§°ï¼ˆå…¼å®¹ä¸åŒçš„é…ç½®æ–¹å¼ï¼‰
        supabase_url = (
            os.getenv('SUPABASE_URL') or 
            os.getenv('NEXT_PUBLIC_SUPABASE_URL')
        )
        supabase_key = (
            os.getenv('SUPABASE_KEY') or 
            os.getenv('SUPABASE_ANON_KEY') or
            os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        )
        
        if not supabase_url or not supabase_key:
            print("âš ï¸  è­¦å‘Š: Supabase é…ç½®æœªæ‰¾åˆ°ï¼Œå°†æ— æ³•ä¿å­˜æ”»ç•¥åˆ°æ•°æ®åº“")
            print("   è¯·è®¾ç½® SUPABASE_URL å’Œ SUPABASE_KEY ç¯å¢ƒå˜é‡")
            return None
        
        supabase = create_client(supabase_url, supabase_key)
        print("âœ… Supabase å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    return supabase

def extract_game_name(question: str) -> Optional[str]:
    """
    ä»é—®é¢˜ä¸­æå–æ¸¸æˆåç§°
    å°è¯•è¯†åˆ«å¸¸è§çš„æ¸¸æˆåç§°æ¨¡å¼
    """
    # å¸¸è§æ¨¡å¼ï¼š<<æ¸¸æˆåç§°>>ã€æ¸¸æˆåç§°æ”»ç•¥ã€å…³äºæ¸¸æˆåç§°ç­‰
    patterns = [
        r'<<([^>>]+)>>',  # <<æ¸¸æˆåç§°>>
        r'ã€Š([^ã€‹]+)ã€‹',    # ã€Šæ¸¸æˆåç§°ã€‹
        r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]+)(?:çš„)?æ”»ç•¥',  # æ¸¸æˆåç§°æ”»ç•¥
        r'å…³äº([^ï¼Œã€‚ï¼ï¼Ÿ\s]+)',  # å…³äºæ¸¸æˆåç§°
    ]
    
    for pattern in patterns:
        match = re.search(pattern, question)
        if match:
            game_name = match.group(1).strip()
            if len(game_name) > 1:  # è‡³å°‘2ä¸ªå­—ç¬¦
                return game_name

    # æå–åœ¨ç–‘é—®è¯/å…³é”®è¯å‰å‡ºç°çš„æ¸¸æˆåï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
    # ç–‘é—®è¯å’Œå…³é”®è¯åˆ—è¡¨
    question_keywords = [
        'æœ‰æ²¡æœ‰', 'æ˜¯ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'æ€æ ·', 'èƒ½å¦', 'å¯å¦', 'æ˜¯å¦',
        'æ”»ç•¥', 'æ€ä¹ˆç©', 'æ€ä¹ˆæ‰“', 'æ€ä¹ˆè¿‡', 'æ‰“æ³•', 'æŠ€å·§', 'é˜µå®¹', 'é…è£…',
        'æµç¨‹', 'ä»»åŠ¡', 'é€šå…³', 'boss', 'BOSS', 'è‹±é›„', 'è§’è‰²', 'éš¾åº¦', 'æ®µä½', 'æ€è·¯',
        'ç§˜ç±', 'ä½œå¼Šç ', 'ä»£ç ', 'æŒ‡ä»¤', 'å‘½ä»¤'
    ]
    
    # ç§»é™¤å¼€å¤´çš„å™ªéŸ³è¯
    leading_noise = r'^(å…³äº|è¯·é—®|æ±‚|æƒ³äº†è§£|å¸®æˆ‘çœ‹çœ‹|é—®ä¸‹|å¬è¯´|æ±‚åŠ©|å¤§ç¥|å„ä½|å¤§å®¶|è¯·æ•™)\s*'
    cleaned_question = re.sub(leading_noise, '', question.strip())
    
    # å°è¯•åŒ¹é…ï¼šæ¸¸æˆå + ç–‘é—®è¯/å…³é”®è¯ + å…¶ä»–å†…å®¹
    for keyword in question_keywords:
        if keyword in cleaned_question:
            # æ‰¾åˆ°å…³é”®è¯çš„ä½ç½®
            keyword_pos = cleaned_question.find(keyword)
            if keyword_pos > 0:
                # æå–å…³é”®è¯ä¹‹å‰çš„éƒ¨åˆ†ä½œä¸ºæ¸¸æˆåå€™é€‰
                candidate = cleaned_question[:keyword_pos].strip()
                # æ¸…ç†å€™é€‰åç§°ï¼ˆç§»é™¤å¯èƒ½çš„æ ‡ç‚¹ç¬¦å·ï¼‰
                candidate = candidate.strip('ã€Šã€‹"ã€Œã€ã€ã€ï¼Œã€‚ï¼ï¼Ÿ?!ï¼›;ï¼š: ')
                # å¦‚æœå€™é€‰åç§°åˆç†ï¼ˆé•¿åº¦åœ¨2-30ä¹‹é—´ï¼Œä¸”ä¸åŒ…å«ç–‘é—®è¯ï¼‰
                if 2 <= len(candidate) <= 30 and not any(qk in candidate for qk in question_keywords):
                    return candidate
    
    # äºŒæ¬¡å¯å‘å¼ï¼šå¦‚æœæ•´å¥è¾ƒçŸ­ä¸”ä¸å«æ˜æ˜¾åŠ¨ä½œè¯/ç–‘é—®è¯ï¼Œç›´æ¥è§†ä¸ºæ¸¸æˆå
    condensed = question.strip().strip('ã€Šã€‹"ã€Œã€ã€ã€')
    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç–‘é—®è¯æˆ–åŠ¨ä½œè¯
    has_question_word = any(kw in condensed for kw in question_keywords)
    if (
        1 < len(condensed) <= 20
        and not re.search(r'[ï¼Ÿ?ï¼!ã€‚ï¼Œ,ï¼›;ï¼š:\n]', condensed)
        and re.search(r'[\u4e00-\u9fa5A-Za-z0-9]', condensed)
        and not has_question_word  # ä¸åŒ…å«ç–‘é—®è¯æ‰è§†ä¸ºæ¸¸æˆå
    ):
        return condensed

    # åˆ†å¥åå°è¯•æå–åœ¨å…³é”®è¯å‰å‡ºç°çš„æ¸¸æˆå
    segments = re.split(r'[ã€‚ï¼ï¼Ÿ?!ï¼›;ï¼Œ,]', question)
    for segment in segments:
        seg = segment.strip()
        if not seg:
            continue
        for keyword in question_keywords:
            if keyword in seg:
                candidate = seg.split(keyword)[0]
                candidate = re.sub(leading_noise, '', candidate).strip('ã€Šã€‹"ã€Œã€ã€ã€ ')
                if len(candidate) >= 2:
                    return candidate

    # å…œåº•ï¼šå°è¯•æŠ“å–è¿ç»­çš„ä¸­æ–‡/å­—æ¯è¯ç»„ä½œä¸ºå€™é€‰ï¼ˆä½†æ’é™¤åŒ…å«ç–‘é—®è¯çš„æƒ…å†µï¼‰
    fallback_match = re.search(r'([\u4e00-\u9fa5A-Za-z0-9][\u4e00-\u9fa5A-Za-z0-9\s]{1,20})', question)
    if fallback_match:
        candidate = fallback_match.group(0).strip()
        # æ£€æŸ¥å€™é€‰æ˜¯å¦åŒ…å«ç–‘é—®è¯ï¼Œå¦‚æœåŒ…å«åˆ™å°è¯•æå–ç–‘é—®è¯ä¹‹å‰çš„éƒ¨åˆ†
        for keyword in question_keywords:
            if keyword in candidate:
                keyword_pos = candidate.find(keyword)
                if keyword_pos > 0:
                    candidate = candidate[:keyword_pos].strip()
                    break
        if len(candidate) >= 2 and not any(kw in candidate for kw in question_keywords):
            return candidate

    return None

def normalize_game_title(name: str) -> str:
    """
    å½’ä¸€åŒ–æ¸¸æˆåç§°ï¼Œç§»é™¤æ‹¬å·/ç©ºæ ¼å¹¶è½¬ä¸ºå°å†™ï¼Œä¾¿äºæ¯”è¾ƒ
    """
    cleaned = re.sub(r'[ã€Šã€‹<>ã€Œã€ã€ã€\s]+', '', name or '')
    return cleaned.lower()

def resolve_game_name(detected_name: Optional[str], fallback_name: Optional[str]) -> Optional[str]:
    """
    æ ¹æ®æ£€æµ‹ç»“æœä¸å·²æœ‰æ”»ç•¥åç§°ï¼Œå†³å®šæœ€ç»ˆç”¨äºå±•ç¤ºçš„æ¸¸æˆå
    è§„åˆ™ï¼šä¼˜å…ˆè¿”å›åŒ…å«æ›´å¤šä¿¡æ¯ï¼ˆæ›´é•¿ä¸”åŒ…å«å…³ç³»ï¼‰çš„åç§°
    """
    if detected_name and fallback_name:
        normalized_detected = normalize_game_title(detected_name)
        normalized_fallback = normalize_game_title(fallback_name)
        
        if normalized_detected in normalized_fallback and len(fallback_name) > len(detected_name):
            return fallback_name
        if normalized_fallback in normalized_detected and len(detected_name) >= len(fallback_name):
            return detected_name
        # ä¸¤è€…ä¸åŒä¸”ä¸å¯åŒ…å«æ—¶ï¼Œä¼˜å…ˆè¿”å›æ£€æµ‹åˆ°çš„ï¼Œä¿è¯ä¸ç”¨æˆ·è¾“å…¥ä¸€è‡´
        return detected_name
    
    return detected_name or fallback_name

def is_direct_game_match(detected_name: Optional[str], fallback_name: Optional[str]) -> bool:
    """
    åˆ¤æ–­æ£€æµ‹åˆ°çš„æ¸¸æˆåä¸å½“å‰æ”»ç•¥åæ˜¯å¦ç›´æ¥åŒ¹é…ï¼ˆå¿½ç•¥ç©ºæ ¼ä¸æ‹¬å·ï¼‰
    """
    if not detected_name or not fallback_name:
        return False
    
    normalized_detected = normalize_game_title(detected_name)
    normalized_fallback = normalize_game_title(fallback_name)
    
    return (
        normalized_detected == normalized_fallback
        or normalized_detected in normalized_fallback
        or normalized_fallback in normalized_detected
    )

def get_current_game_name() -> Optional[str]:
    """
    ä» guide.txt ä¸­è¯»å–å½“å‰æ¸¸æˆåç§°
    """
    global current_game_name
    
    if current_game_name:
        return current_game_name
    
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        guide_path = os.path.join(script_dir, 'guide.txt')
        
        if os.path.exists(guide_path):
            with open(guide_path, 'r', encoding='utf-8') as f:
                first_line = f.readline().strip()
                # æå– <<æ¸¸æˆåç§°>> æ ¼å¼
                match = re.search(r'<<([^>>]+)>>', first_line)
                if match:
                    current_game_name = match.group(1).strip()
                    return current_game_name
    except Exception as e:
        print(f"è¯»å–æ¸¸æˆåç§°æ—¶å‡ºé”™: {e}")
    
    return None

def check_game_match(question: str, rag_chunks: List[str]) -> bool:
    """
    æ£€æŸ¥ RAG å†…å®¹æ˜¯å¦é€‚ç”¨äºé—®é¢˜ä¸­çš„æ¸¸æˆ
    è¿”å› True å¦‚æœåŒ¹é…ï¼ŒFalse å¦‚æœä¸åŒ¹é…
    """
    # æå–é—®é¢˜ä¸­çš„æ¸¸æˆåç§°
    question_game = extract_game_name(question)
    
    # è·å–å½“å‰æ”»ç•¥çš„æ¸¸æˆåç§°
    current_game = get_current_game_name()
    
    # å¦‚æœé—®é¢˜ä¸­æ²¡æœ‰æ¸¸æˆåç§°ï¼Œå‡è®¾åŒ¹é…
    if not question_game:
        return True
    
    # å¦‚æœå½“å‰æ”»ç•¥æ²¡æœ‰æ¸¸æˆåç§°ï¼Œå‡è®¾ä¸åŒ¹é…
    if not current_game:
        return False
    
    # æ£€æŸ¥æ¸¸æˆåç§°æ˜¯å¦åŒ¹é…ï¼ˆä½¿ç”¨ç›¸ä¼¼åº¦åˆ¤æ–­ï¼‰
    if model:
        try:
            # å°†æ¸¸æˆåç§°è½¬æ¢ä¸ºå‘é‡å¹¶è®¡ç®—ç›¸ä¼¼åº¦
            question_vec = model.encode([question_game])[0]
            current_vec = model.encode([current_game])[0]
            
            similarity = np.dot(question_vec, current_vec) / (
                np.linalg.norm(question_vec) * np.linalg.norm(current_vec)
            )
            
            # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼š0.6 ä»¥ä¸Šè®¤ä¸ºåŒ¹é…
            is_match = similarity >= 0.6
            
            print(f"ğŸ® æ¸¸æˆåŒ¹é…æ£€æµ‹:")
            print(f"   é—®é¢˜ä¸­çš„æ¸¸æˆ: {question_game}")
            print(f"   å½“å‰æ”»ç•¥æ¸¸æˆ: {current_game}")
            print(f"   ç›¸ä¼¼åº¦: {similarity:.4f}")
            print(f"   åŒ¹é…ç»“æœ: {'âœ… åŒ¹é…' if is_match else 'âŒ ä¸åŒ¹é…'}")
            
            return is_match
        except Exception as e:
            print(f"æ¸¸æˆåŒ¹é…æ£€æµ‹å‡ºé”™: {e}")
            # å‡ºé”™æ—¶ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
            return question_game.lower() in current_game.lower() or current_game.lower() in question_game.lower()
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
    return question_game.lower() in current_game.lower() or current_game.lower() in question_game.lower()

def generate_guide_with_llm(game_name: str, question: str) -> str:
    """
    ä½¿ç”¨ LLM ç”Ÿæˆæ–°æ¸¸æˆçš„æ”»ç•¥
    """
    api_key = os.getenv('DEEPSEEK_API_KEY')
    
    if not api_key:
        return "æ— æ³•ç”Ÿæˆæ”»ç•¥ï¼šæœªé…ç½® DEEPSEEK_API_KEY"
    
    try:
        openai.api_base = "https://api.deepseek.com/v1"
        openai.api_key = api_key
        
        prompt = f"""ä½ æ˜¯ä¸€åç¡¬æ ¸æ¸¸æˆæ”»ç•¥æ’°å†™ä¸“å®¶ã€‚å½“å‰æ£€æµ‹åˆ°ç”¨æˆ·è¯¢é—®çš„æ¸¸æˆã€Š{game_name}ã€‹ä¸ç°æœ‰ RAG æ”»ç•¥åº“ä¸åŒ¹é…ï¼Œè¯·ä¸ºè¿™æ¬¾æ¸¸æˆé‡æ–°ç”Ÿæˆå®Œæ•´æ”»ç•¥ã€‚è¯·å‚è€ƒä»¥ä¸‹ç»“æ„è¾“å‡º Markdown å†…å®¹ï¼Œå¹¶ç¡®ä¿ç”¨è¯ä¸“ä¸šã€æ¡ç†æ¸…æ™°ï¼š

## ğŸ® æ¸¸æˆæ¦‚è§ˆ
- ç®€è¿°æ¸¸æˆç±»å‹ã€èƒŒæ™¯ã€æ ¸å¿ƒç‰¹è‰²

## ğŸ’¡ æ–°æ‰‹å¿…è¯»
- 3-5 æ¡å…¥é—¨å…³é”®æŠ€å·§ï¼ˆæ“ä½œã€ç³»ç»Ÿã€èµ„æºï¼‰

## âš”ï¸ æ ¸å¿ƒæœºåˆ¶è§£æ
- è¯´æ˜æˆ˜æ–—/å…»æˆ/ç³»ç»Ÿç©æ³•ï¼Œç»™å‡ºç¤ºä¾‹æˆ–ä¼˜å…ˆçº§

## ğŸ—ºï¸ ä»»åŠ¡ä¸è¿›åº¦æŒ‡å¼•
- é‡è¦ä¸»çº¿/æ”¯çº¿ã€å°è´´å£«æˆ–æµç¨‹å»ºè®®

## ğŸ”¥ è¿›é˜¶ä¸æˆå°±æŠ€å·§
- é«˜éš¾åº¦æŒ‘æˆ˜ã€è£…å¤‡æ­é…ã€åˆ·èµ„æºç­–ç•¥

é¢å¤–è¦æ±‚ï¼š
- å¿…é¡»é’ˆå¯¹ã€Š{game_name}ã€‹ç¼–å†™ï¼Œè€Œä¸æ˜¯å…¶ä»–æ¸¸æˆ
- å¯ä»¥ç»“åˆç”¨æˆ·é—®é¢˜æä¾›çš„ä¸Šä¸‹æ–‡ï¼š{question}
- ä¿æŒ Markdown ç»“æ„ï¼Œä½¿ç”¨å¿…è¦çš„åŠ ç²—ã€åˆ—è¡¨ã€è¡¨æƒ…ç¬¦å·å¢å¼ºå¯è¯»æ€§
- ä¸­æ–‡å›ç­”"""

        response = openai.ChatCompletion.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¸¸æˆæ”»ç•¥æ’°å†™è€…ï¼Œæ“…é•¿æ’°å†™è¯¦ç»†ã€å®ç”¨çš„æ¸¸æˆæ”»ç•¥ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        guide = response.choices[0].message.content.strip()
        return guide
    except Exception as e:
        print(f"ç”Ÿæˆæ”»ç•¥æ—¶å‡ºé”™: {e}")
        return f"ç”Ÿæˆæ”»ç•¥æ—¶å‡ºé”™: {str(e)}"

def save_guide_to_supabase(game_name: str, guide_content: str, question: str) -> bool:
    """
    å°†ç”Ÿæˆçš„æ”»ç•¥ä¿å­˜åˆ° Supabase
    """
    global supabase
    
    if supabase is None:
        supabase = init_supabase()
    
    if supabase is None:
        print("âš ï¸  Supabase æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜æ”»ç•¥")
        return False
    
    try:
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æ¸¸æˆçš„æ”»ç•¥
        existing = supabase.table('game_guides').select('*').eq('game_name', game_name).execute()
        
        data = {
            'game_name': game_name,
            'guide_content': guide_content,
            'question': question,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        if existing.data and len(existing.data) > 0:
            # æ›´æ–°ç°æœ‰æ”»ç•¥
            result = supabase.table('game_guides').update(data).eq('game_name', game_name).execute()
            print(f"âœ… å·²æ›´æ–°æ¸¸æˆã€Š{game_name}ã€‹çš„æ”»ç•¥åˆ° Supabase")
        else:
            # æ’å…¥æ–°æ”»ç•¥
            result = supabase.table('game_guides').insert(data).execute()
            print(f"âœ… å·²ä¿å­˜æ¸¸æˆã€Š{game_name}ã€‹çš„æ”»ç•¥åˆ° Supabase")
        
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜æ”»ç•¥åˆ° Supabase æ—¶å‡ºé”™: {e}")
        return False

def load_model():
    """
    åŠ è½½ sentence-transformers æ¨¡å‹
    """
    global model
    if model is None:
        print("æ­£åœ¨åŠ è½½ sentence-transformers æ¨¡å‹...")
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        print("æ¨¡å‹åŠ è½½å®Œæˆ")

def find_similar_chunks(question: str, top_k: int = 3, similarity_threshold: float = 0.3, target_game_name: Optional[str] = None) -> Tuple[List[str], float]:
    """
    åœ¨å‘é‡ä¸­æœç´¢æœ€ç›¸ä¼¼çš„æ®µè½
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. å¦‚æœæŒ‡å®šäº†æ¸¸æˆåç§°ï¼Œåªæœç´¢è¯¥æ¸¸æˆçš„ chunks
    2. ä½¿ç”¨æ›´å®½æ¾çš„ top_k æœç´¢ï¼ˆå…ˆæ‰¾æ›´å¤šå€™é€‰ï¼‰
    3. ç„¶åæ ¹æ®ç›¸ä¼¼åº¦è¿‡æ»¤
    è¿”å›: (ç›¸å…³æ®µè½åˆ—è¡¨, æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°)
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        top_k: è¿”å›æœ€ç›¸ä¼¼çš„æ®µè½æ•°é‡
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        target_game_name: ç›®æ ‡æ¸¸æˆåç§°ï¼Œå¦‚æœæä¾›åˆ™åªæœç´¢è¯¥æ¸¸æˆçš„ chunks
    """
    if model is None or chunks is None or embeddings is None:
        raise RuntimeError("æ¨¡å‹æˆ–å‘é‡æœªåŠ è½½")
    
    # å¦‚æœæŒ‡å®šäº†æ¸¸æˆåç§°ï¼Œå…ˆè¿‡æ»¤å‡ºå±äºè¯¥æ¸¸æˆçš„ chunks
    valid_indices = None
    if target_game_name and chunk_game_names:
        normalized_target = normalize_game_title(target_game_name)
        valid_indices = [
            i for i, game_name in enumerate(chunk_game_names)
            if game_name and normalize_game_title(game_name) == normalized_target
        ]
        
        if not valid_indices:
            print(f"âš ï¸  æœªæ‰¾åˆ°æ¸¸æˆã€Š{target_game_name}ã€‹çš„æ”»ç•¥æ®µè½ï¼Œå°†æœç´¢æ‰€æœ‰å†…å®¹")
            valid_indices = None
        else:
            print(f"ğŸ® å·²è¿‡æ»¤å‡º {len(valid_indices)} ä¸ªã€Š{target_game_name}ã€‹çš„æ”»ç•¥æ®µè½")
    
    # å°†é—®é¢˜è½¬æ¢ä¸ºå‘é‡
    question_embedding = model.encode([question])[0]
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆåªè®¡ç®—æœ‰æ•ˆç´¢å¼•çš„ç›¸ä¼¼åº¦ï¼‰
    if valid_indices is not None:
        # åªè®¡ç®—ç›®æ ‡æ¸¸æˆçš„ chunks çš„ç›¸ä¼¼åº¦
        valid_embeddings = embeddings[valid_indices]
        similarities_all = np.zeros(len(chunks))
        valid_similarities = np.dot(valid_embeddings, question_embedding) / (
            np.linalg.norm(valid_embeddings, axis=1) * np.linalg.norm(question_embedding)
        )
        # å°†ç›¸ä¼¼åº¦æ˜ å°„å›åŸå§‹ç´¢å¼•
        for idx, orig_idx in enumerate(valid_indices):
            similarities_all[orig_idx] = valid_similarities[idx]
        similarities = similarities_all
        # åªä»æœ‰æ•ˆç´¢å¼•ä¸­é€‰æ‹©
        candidate_indices = valid_indices
    else:
        # è®¡ç®—æ‰€æœ‰ chunks çš„ç›¸ä¼¼åº¦
        similarities = np.dot(embeddings, question_embedding) / (
            np.linalg.norm(embeddings, axis=1) * np.linalg.norm(question_embedding)
        )
        candidate_indices = list(range(len(chunks)))
    
    # å…ˆè·å–æ›´å¤šçš„å€™é€‰ï¼ˆtop_k * 2ï¼‰ï¼Œç„¶åè¿‡æ»¤
    candidate_count = min(top_k * 2, len(candidate_indices))
    # åªä»å€™é€‰ç´¢å¼•ä¸­é€‰æ‹©
    candidate_similarities = similarities[candidate_indices]
    top_local_indices = np.argsort(candidate_similarities)[-candidate_count:][::-1]
    top_indices = [candidate_indices[i] for i in top_local_indices]
    
    # è·å–æœ€é«˜ç›¸ä¼¼åº¦
    max_similarity = similarities[top_indices[0]] if len(top_indices) > 0 else 0.0
    
    # æ™ºèƒ½é€‰æ‹©ç­–ç•¥ï¼š
    # 1. å¦‚æœæœ€é«˜ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜ï¼Œè¿”å› top_k ä¸ªæœ€ç›¸ä¼¼çš„
    # 2. å¦‚æœç›¸ä¼¼åº¦ä¸å¤Ÿï¼Œä½†æœ‰ä¸€äº›æ®µè½ç›¸ä¼¼åº¦è¿˜å¯ä»¥ï¼Œè¿”å›è¿™äº›æ®µè½
    # 3. å¦‚æœç›¸ä¼¼åº¦éƒ½å¾ˆä½ï¼Œè‡³å°‘è¿”å› 1 ä¸ªæœ€ç›¸ä¼¼çš„ï¼ˆå¯èƒ½ä½¿ç”¨ LLM é€šç”¨çŸ¥è¯†ï¼‰
    if max_similarity >= similarity_threshold:
        # ç›¸ä¼¼åº¦è¶³å¤Ÿï¼Œè¿”å› top_k ä¸ª
        selected_indices = top_indices[:top_k]
    else:
        # ç›¸ä¼¼åº¦ä¸å¤Ÿï¼Œä½¿ç”¨æ›´å®½æ¾çš„ç­–ç•¥
        # è®¡ç®—åŠ¨æ€é˜ˆå€¼ï¼šæœ€é«˜ç›¸ä¼¼åº¦çš„ 70%
        dynamic_threshold = max_similarity * 0.7 if max_similarity > 0 else 0.1
        
        # è¿”å›æ‰€æœ‰è¶…è¿‡åŠ¨æ€é˜ˆå€¼çš„æ®µè½ï¼ˆè‡³å°‘ 1 ä¸ªï¼‰
        selected_indices = [idx for idx in top_indices if similarities[idx] >= dynamic_threshold]
        
        if not selected_indices:
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè‡³å°‘è¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„ 1 ä¸ª
            selected_indices = [top_indices[0]] if len(top_indices) > 0 else []
        else:
            # é™åˆ¶æ•°é‡ï¼Œä½†è‡³å°‘è¿”å› 1 ä¸ª
            selected_indices = selected_indices[:top_k]
    
    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"ğŸ” æœç´¢é—®é¢˜: {question}")
    if target_game_name:
        print(f"ğŸ® ç›®æ ‡æ¸¸æˆ: {target_game_name}")
    print(f"{'='*60}")
    print(f"æ‰¾åˆ° {len(selected_indices)} ä¸ªç›¸å…³æ®µè½:")
    for idx, i in enumerate(selected_indices):
        game_info = f" [{chunk_game_names[i] if chunk_game_names and i < len(chunk_game_names) else 'æœªçŸ¥'}]" if chunk_game_names else ""
        print(f"  [{idx+1}] ç›¸ä¼¼åº¦: {similarities[i]:.4f}{game_info}")
        print(f"      å†…å®¹: {chunks[i][:100]}..." if len(chunks[i]) > 100 else f"      å†…å®¹: {chunks[i]}")
        print()
    print(f"æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.4f} (é˜ˆå€¼: {similarity_threshold:.4f})")
    if max_similarity >= similarity_threshold:
        print("âœ… ç›¸ä¼¼åº¦è¶³å¤Ÿï¼Œå°†ä¼˜å…ˆä½¿ç”¨ RAG å†…å®¹å›ç­”")
    else:
        print("âš ï¸  ç›¸ä¼¼åº¦è¾ƒä½ï¼Œä½†ä»ä¼šä½¿ç”¨æ‰¾åˆ°çš„ RAG å†…å®¹ï¼ˆå¯èƒ½è¡¥å……é€šç”¨çŸ¥è¯†ï¼‰")
    print(f"{'='*60}\n")
    
    return [chunks[i] for i in selected_indices], max_similarity

def get_llm_response(question: str, context_chunks: List[str], use_rag: bool = True) -> str:
    """
    å°†é—®é¢˜å’Œç›¸å…³æ®µè½å‘é€ç»™ Deepseek LLM ç”Ÿæˆå›ç­”
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        context_chunks: ç›¸å…³æ®µè½åˆ—è¡¨
        use_rag: æ˜¯å¦ä½¿ç”¨ RAG å†…å®¹ï¼ˆTrue=ä¸¥æ ¼ä½¿ç”¨æ”»ç•¥ï¼ŒFalse=ä½¿ç”¨é€šç”¨çŸ¥è¯†ï¼‰
    """
    if use_rag and context_chunks:
        # ä½¿ç”¨ RAG å†…å®¹å›ç­”
        context = "\n\n".join([f"æ®µè½ {i+1}: {chunk}" for i, chunk in enumerate(context_chunks)])
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆæ”»ç•¥åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ”»ç•¥å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

ã€æ”»ç•¥å†…å®¹ã€‘
{context}
ã€æ”»ç•¥å†…å®¹ç»“æŸã€‘

ç”¨æˆ·é—®é¢˜ï¼š{question}

å›ç­”è§„åˆ™ï¼š
1. ä¼˜å…ˆä½¿ç”¨ä¸Šè¿°æ”»ç•¥å†…å®¹ä¸­çš„ä¿¡æ¯å›ç­”
2. å¦‚æœæ”»ç•¥ä¸­æœ‰ç›¸å…³å†…å®¹ï¼Œè¯·ç›´æ¥å¼•ç”¨æˆ–è½¬è¿°æ”»ç•¥å†…å®¹
3. å¦‚æœæ”»ç•¥ä¸­çš„ä¿¡æ¯ä¸å¤Ÿå®Œæ•´ï¼Œå¯ä»¥é€‚å½“è¡¥å……åˆç†çš„æ¸¸æˆå¸¸è¯†ï¼Œä½†è¦æ˜ç¡®åŒºåˆ†å“ªäº›æ˜¯æ”»ç•¥å†…å®¹ï¼Œå“ªäº›æ˜¯è¡¥å……è¯´æ˜
4. å›ç­”è¦è¯¦ç»†ã€å‡†ç¡®ã€å®ç”¨ï¼Œå°½é‡æä¾›å®Œæ•´çš„ç­”æ¡ˆ
5. å¦‚æœæ”»ç•¥å†…å®¹ä¸é—®é¢˜ç›¸å…³åº¦ä¸é«˜ï¼Œå¯ä»¥åŸºäºæ”»ç•¥å†…å®¹è¿›è¡Œåˆç†æ¨æ–­

ç°åœ¨è¯·åŸºäºæ”»ç•¥å†…å®¹å›ç­”ï¼š"""
    else:
        # ä½¿ç”¨ LLM é€šç”¨çŸ¥è¯†å›ç­”
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¸¸æˆæ”»ç•¥åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„æ¸¸æˆçŸ¥è¯†å’Œç»éªŒã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä½ çš„æ¸¸æˆçŸ¥è¯†ï¼Œæä¾›ä¸“ä¸šã€è¯¦ç»†çš„å›ç­”ã€‚å›ç­”è¦ï¼š
1. å‡†ç¡®ã€å®ç”¨
2. ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£
3. åŒ…å«å…·ä½“çš„å»ºè®®å’ŒæŠ€å·§
4. å¦‚æœé—®é¢˜æ¶‰åŠç‰¹å®šæ¸¸æˆï¼Œè¯·æä¾›é€šç”¨çš„æ¸¸æˆç­–ç•¥å’Œæ€è·¯

è¯·å›ç­”ï¼š"""

    # ä½¿ç”¨ Deepseek API
    api_key = os.getenv('DEEPSEEK_API_KEY')
    
    if api_key:
        try:
            # é…ç½® Deepseek API
            openai.api_base = "https://api.deepseek.com/v1"
            openai.api_key = api_key
            
            # ä½¿ç”¨æ›´ä½çš„ temperature è®©å›ç­”æ›´ç¡®å®šï¼Œæ›´ä¸¥æ ¼éµå¾ªæ”»ç•¥
            response = openai.ChatCompletion.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆæ”»ç•¥åŠ©æ‰‹ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·æä¾›çš„æ”»ç•¥å†…å®¹å›ç­”é—®é¢˜ï¼Œä¸èƒ½æ·»åŠ æ”»ç•¥ä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚å¦‚æœæ”»ç•¥ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¿…é¡»æ˜ç¡®è¯´æ˜ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œè®©å›ç­”æ›´ç¡®å®š
                max_tokens=500
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Deepseek API è°ƒç”¨å¤±è´¥: {str(e)}ã€‚è¯·æ£€æŸ¥ API å¯†é’¥é…ç½®ã€‚"
    else:
        # å¦‚æœæ²¡æœ‰é…ç½® APIï¼Œè¿”å›ä¸€ä¸ªç®€å•çš„åŸºäºè§„åˆ™çš„å›ç­”
        return f"æ ¹æ®æ”»ç•¥å†…å®¹ï¼š{context_chunks[0] if context_chunks else 'æ— ç›¸å…³å†…å®¹'}ï¼Œå›ç­”æ‚¨çš„é—®é¢˜ï¼š{question}ã€‚\n\nï¼ˆæç¤ºï¼šè¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨å®Œæ•´çš„ LLM åŠŸèƒ½ï¼‰"

@app.on_event("startup")
async def startup_event():
    """
    åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹å’Œå‘é‡
    """
    load_model()
    init_supabase()
    try:
        load_vectors()
    except FileNotFoundError as e:
        print(f"è­¦å‘Š: {e}")

@app.get("/")
async def root():
    return {"message": "RAG é—®ç­”ç³»ç»Ÿ API", "status": "running"}

@app.post("/ask", response_model=QuestionResponse)
async def ask_question(request: QuestionRequest):
    """
    æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œåœ¨å‘é‡ä¸­æœç´¢æœ€ç›¸ä¼¼çš„æ®µè½ï¼Œç„¶åä½¿ç”¨ LLM å›ç­”
    
    é€»è¾‘æµç¨‹ï¼š
    1. æå–é—®é¢˜ä¸­çš„æ¸¸æˆåç§°
    2. æœç´¢ RAG ç›¸å…³å†…å®¹
    3. æ£€æŸ¥ RAG å†…å®¹æ˜¯å¦é€‚ç”¨äºè¾“å…¥çš„æ¸¸æˆ
    4. å¦‚æœä¸é€‚ç”¨ï¼Œä½¿ç”¨ LLM ç”Ÿæˆæ–°æ”»ç•¥å¹¶ä¿å­˜åˆ° Supabase
    5. å¦‚æœé€‚ç”¨ï¼Œä½¿ç”¨ RAG å†…å®¹å›ç­”
    """
    try:
        # æå–æ¸¸æˆåç§°
        game_name = extract_game_name(request.question)
        current_game = get_current_game_name()
        resolved_game_name = resolve_game_name(game_name, current_game)
        print(f"\n{'='*60}")
        print(f"ğŸ® æ£€æµ‹åˆ°çš„æ¸¸æˆåç§°: {game_name or 'æœªæ£€æµ‹åˆ°'}")
        print(f"{'='*60}")
        
        # ç›¸ä¼¼åº¦é˜ˆå€¼
        SIMILARITY_THRESHOLD = 0.7
        
        # å¦‚æœæ£€æµ‹åˆ°æ¸¸æˆåç§°ï¼Œåªæœç´¢è¯¥æ¸¸æˆçš„æ”»ç•¥
        target_game = resolved_game_name or game_name
        
        # æœç´¢æœ€ç›¸ä¼¼çš„æ®µè½ï¼ˆå¦‚æœæ£€æµ‹åˆ°æ¸¸æˆåç§°ï¼Œåªæœç´¢è¯¥æ¸¸æˆçš„ chunksï¼‰
        relevant_chunks, max_similarity = find_similar_chunks(
            request.question, 
            request.top_k,
            similarity_threshold=SIMILARITY_THRESHOLD,
            target_game_name=target_game  # ä¼ å…¥ç›®æ ‡æ¸¸æˆåç§°ï¼Œå®ç°æŒ‰æ¸¸æˆè¿‡æ»¤
        )
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ RAG
        use_rag = len(relevant_chunks) > 0
        
        # å¦‚æœæ‰¾åˆ°äº† RAG å†…å®¹ï¼Œæ£€æŸ¥æ¸¸æˆæ˜¯å¦åŒ¹é…
        direct_text_match = is_direct_game_match(game_name, current_game)
        skip_game_match_check = direct_text_match and max_similarity >= SIMILARITY_THRESHOLD
        
        if use_rag and game_name and not skip_game_match_check:
            is_game_match = check_game_match(request.question, relevant_chunks)
            
            if not is_game_match:
                # RAG å†…å®¹ä¸é€‚ç”¨äºè¾“å…¥çš„æ¸¸æˆï¼Œç”Ÿæˆæ–°æ”»ç•¥
                print(f"\n{'='*60}")
                print(f"âš ï¸  RAG å†…å®¹ä¸é€‚ç”¨äºæ¸¸æˆã€Š{game_name}ã€‹ï¼Œå°†ç”Ÿæˆæ–°æ”»ç•¥")
                print(f"{'='*60}\n")
                
                # ç”Ÿæˆæ–°æ”»ç•¥
                new_guide = generate_guide_with_llm(game_name, request.question)
                
                # ä¿å­˜åˆ° Supabase
                save_success = save_guide_to_supabase(game_name, new_guide, request.question)
                
                if save_success:
                    print(f"âœ… æ–°æ”»ç•¥å·²ä¿å­˜åˆ° Supabase")
                else:
                    print(f"âš ï¸  æ–°æ”»ç•¥ç”ŸæˆæˆåŠŸï¼Œä½†ä¿å­˜åˆ° Supabase å¤±è´¥")
                
                return QuestionResponse(
                    answer=new_guide,
                    relevant_chunks=[],
                    source="llm_generated",
                    game_name=resolved_game_name or game_name
                )
        
        # ä½¿ç”¨ RAG å†…å®¹å›ç­”
        if use_rag:
            if max_similarity >= SIMILARITY_THRESHOLD:
                print(f"ğŸ“ ä½¿ç”¨ RAG æ¨¡å¼ï¼ˆé«˜ç›¸ä¼¼åº¦ {max_similarity:.4f}ï¼‰- å‘é€ç»™ LLM çš„ä¸Šä¸‹æ–‡:")
            else:
                print(f"ğŸ“ ä½¿ç”¨ RAG æ¨¡å¼ï¼ˆç›¸ä¼¼åº¦è¾ƒä½ {max_similarity:.4f}ï¼Œä½†ä»ä½¿ç”¨æ‰¾åˆ°çš„å†…å®¹ï¼‰- å‘é€ç»™ LLM çš„ä¸Šä¸‹æ–‡:")
            for i, chunk in enumerate(relevant_chunks):
                print(f"  æ®µè½ {i+1}: {chunk}")
            print()
            answer = get_llm_response(request.question, relevant_chunks, use_rag=True)
            source = "rag"
        else:
            # ä½¿ç”¨ LLM é€šç”¨çŸ¥è¯†å›ç­”ï¼ˆå®Œå…¨æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ®µè½ï¼‰
            print(f"ğŸ“ ä½¿ç”¨ LLM é€šç”¨çŸ¥è¯†æ¨¡å¼ï¼ˆæœªæ‰¾åˆ°ç›¸å…³æ®µè½ï¼‰")
            print()
            answer = get_llm_response(request.question, [], use_rag=False)
            relevant_chunks = []
            source = "llm_general"
        
        print(f"âœ… LLM ç”Ÿæˆçš„å›ç­”:")
        print(f"   {answer}")
        print(f"{'='*60}\n")
        
        return QuestionResponse(
            answer=answer,
            relevant_chunks=relevant_chunks,
            source=source,
            game_name=resolved_game_name or game_name
        )
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "vectors_loaded": chunks is not None and embeddings is not None,
        "chunks_count": len(chunks) if chunks else 0
    }

if __name__ == '__main__':
    import uvicorn
    print("\n" + "="*50)
    print("ğŸš€ FastAPI æœåŠ¡å¯åŠ¨ä¸­...")
    print("="*50)
    print(f"ğŸ“– API æ–‡æ¡£: http://localhost:8000/docs")
    print(f"â¤ï¸  å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print(f"ğŸŒ æœåŠ¡åœ°å€: http://localhost:8000")
    print("="*50 + "\n")
    # ä½¿ç”¨å¯¼å…¥å­—ç¬¦ä¸²æ–¹å¼ä»¥æ”¯æŒ reload
    uvicorn.run("index:app", host="127.0.0.1", port=8000, reload=True)

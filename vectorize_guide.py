"""
å°† guide.txt æ–‡ä»¶å‘é‡åŒ–ï¼Œç”Ÿæˆ guide_vectors.json
"""
import os
import json
import re
from sentence_transformers import SentenceTransformer
import numpy as np

def split_text_into_chunks(text: str, chunk_size: int = 200, overlap: int = 50) -> list:
    """
    å°†æ–‡æœ¬åˆ†å‰²æˆ chunks
    chunk_size: æ¯ä¸ª chunk çš„å­—ç¬¦æ•°
    overlap: chunks ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
    """
    chunks = []
    
    # æŒ‰æ®µè½åˆ†å‰²ï¼ˆä¿ç•™æ¢è¡Œç¬¦ï¼‰
    paragraphs = text.split('\n\n')
    
    current_chunk = ""
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # å¦‚æœå½“å‰ chunk åŠ ä¸Šæ–°æ®µè½ä¸è¶…è¿‡ chunk_sizeï¼Œåˆ™æ·»åŠ 
        if len(current_chunk) + len(para) + 2 <= chunk_size:
            if current_chunk:
                current_chunk += "\n\n" + para
            else:
                current_chunk = para
        else:
            # å¦‚æœå½“å‰ chunk ä¸ä¸ºç©ºï¼Œä¿å­˜å®ƒ
            if current_chunk:
                chunks.append(current_chunk)
            
            # å¦‚æœæ–°æ®µè½æœ¬èº«å°±å¾ˆé•¿ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
            if len(para) > chunk_size:
                # æŒ‰å¥å­åˆ†å‰²é•¿æ®µè½
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]\s*', para)
                current_chunk = ""
                for sentence in sentences:
                    sentence = sentence.strip()
                    if not sentence:
                        continue
                    
                    if len(current_chunk) + len(sentence) + 1 <= chunk_size:
                        if current_chunk:
                            current_chunk += " " + sentence
                        else:
                            current_chunk = sentence
                    else:
                        if current_chunk:
                            chunks.append(current_chunk)
                        current_chunk = sentence
            else:
                current_chunk = para
    
    # æ·»åŠ æœ€åä¸€ä¸ª chunk
    if current_chunk:
        chunks.append(current_chunk)
    
    # åº”ç”¨é‡å ç­–ç•¥ï¼šå¦‚æœ chunks ä¹‹é—´æœ‰é‡å ï¼Œå¯ä»¥ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
    if overlap > 0 and len(chunks) > 1:
        overlapped_chunks = [chunks[0]]
        for i in range(1, len(chunks)):
            prev_chunk = chunks[i-1]
            current_chunk = chunks[i]
            
            # å–å‰ä¸€ä¸ª chunk çš„æœ€å overlap ä¸ªå­—ç¬¦
            if len(prev_chunk) > overlap:
                overlap_text = prev_chunk[-overlap:]
                overlapped_chunk = overlap_text + " " + current_chunk
            else:
                overlapped_chunk = current_chunk
            
            overlapped_chunks.append(overlapped_chunk)
        chunks = overlapped_chunks
    
    return chunks

def load_guide_file(guide_file: str = 'guide.txt') -> str:
    """
    åŠ è½½ guide.txt æ–‡ä»¶
    """
    script_dir = os.path.dirname(os.path.abspath(__file__))
    guide_path = os.path.join(script_dir, guide_file)
    
    if not os.path.exists(guide_path):
        raise FileNotFoundError(f"æ–‡ä»¶ {guide_path} ä¸å­˜åœ¨")
    
    with open(guide_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    return content

def vectorize_guide(guide_file: str = 'guide.txt', output_file: str = 'guide_vectors.json', 
                    chunk_size: int = 200, overlap: int = 50):
    """
    å°† guide.txt å‘é‡åŒ–å¹¶ä¿å­˜åˆ° guide_vectors.json
    
    Args:
        guide_file: è¾“å…¥çš„æ”»ç•¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºçš„å‘é‡æ–‡ä»¶è·¯å¾„
        chunk_size: æ¯ä¸ª chunk çš„å­—ç¬¦æ•°
        overlap: chunks ä¹‹é—´çš„é‡å å­—ç¬¦æ•°
    """
    print("=" * 60)
    print("ğŸš€ å¼€å§‹å‘é‡åŒ–æ”»ç•¥æ–‡ä»¶...")
    print("=" * 60)
    
    # 1. åŠ è½½æ”»ç•¥æ–‡ä»¶
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ {guide_file}...")
    text = load_guide_file(guide_file)
    print(f"âœ… å·²åŠ è½½ï¼Œæ–‡ä»¶å¤§å°: {len(text)} å­—ç¬¦")
    
    # 2. åˆ†å‰²æˆ chunks
    print(f"\nğŸ“ æ­£åœ¨å°†æ–‡æœ¬åˆ†å‰²æˆ chunks (chunk_size={chunk_size}, overlap={overlap})...")
    chunks = split_text_into_chunks(text, chunk_size=chunk_size, overlap=overlap)
    print(f"âœ… å·²åˆ†å‰²æˆ {len(chunks)} ä¸ª chunks")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ª chunks çš„é¢„è§ˆ
    print("\nå‰ 3 ä¸ª chunks é¢„è§ˆ:")
    for i, chunk in enumerate(chunks[:3]):
        print(f"  [{i+1}] {chunk[:100]}..." if len(chunk) > 100 else f"  [{i+1}] {chunk}")
    
    # 3. åŠ è½½æ¨¡å‹
    print(f"\nğŸ¤– æ­£åœ¨åŠ è½½ sentence-transformers æ¨¡å‹...")
    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # 4. ç”Ÿæˆå‘é‡
    print(f"\nğŸ”¢ æ­£åœ¨ä¸º {len(chunks)} ä¸ª chunks ç”Ÿæˆå‘é‡...")
    embeddings = model.encode(chunks, show_progress_bar=True)
    print(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼Œå‘é‡ç»´åº¦: {embeddings.shape}")
    
    # 5. ä¿å­˜åˆ° JSON æ–‡ä»¶
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(script_dir, output_file)
    
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {output_path}...")
    
    # å°† numpy æ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨ï¼ˆJSON å¯åºåˆ—åŒ–ï¼‰
    data = {
        'chunks': chunks,
        'embeddings': embeddings.tolist()
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å·²ä¿å­˜åˆ° {output_path}")
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€» chunks æ•°: {len(chunks)}")
    print(f"   - å‘é‡ç»´åº¦: {embeddings.shape[1]}")
    print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
    print("=" * 60)
    print("ğŸ‰ å‘é‡åŒ–å®Œæˆï¼")
    print("=" * 60)

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='å°† guide.txt å‘é‡åŒ–')
    parser.add_argument('--guide', type=str, default='guide.txt', 
                       help='è¾“å…¥çš„æ”»ç•¥æ–‡ä»¶è·¯å¾„ (é»˜è®¤: guide.txt)')
    parser.add_argument('--output', type=str, default='guide_vectors.json',
                       help='è¾“å‡ºçš„å‘é‡æ–‡ä»¶è·¯å¾„ (é»˜è®¤: guide_vectors.json)')
    parser.add_argument('--chunk-size', type=int, default=200,
                       help='æ¯ä¸ª chunk çš„å­—ç¬¦æ•° (é»˜è®¤: 200)')
    parser.add_argument('--overlap', type=int, default=50,
                       help='chunks ä¹‹é—´çš„é‡å å­—ç¬¦æ•° (é»˜è®¤: 50)')
    
    args = parser.parse_args()
    
    vectorize_guide(
        guide_file=args.guide,
        output_file=args.output,
        chunk_size=args.chunk_size,
        overlap=args.overlap
    )

